{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separación para análisis por persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import Annotator, colors\n",
    "\n",
    "ruta_utils = \"../src/utils\"\n",
    "\n",
    "# Agregar la ruta al sys.path\n",
    "if ruta_utils not in sys.path:\n",
    "    sys.path.append(ruta_utils)\n",
    "\n",
    "# Ahora puedes importar utils\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../src/models/yolo11n.pt\"\n",
    "video_path = \"../data/robo1.mp4\"\n",
    "output_path = \"../data/output_robo1_yolo.mp4\"\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Open the video file and get properties\n",
    "cap = utils.initialize_video_capture(video_path)\n",
    "w, h, fps = utils.get_video_properties(cap)\n",
    "\n",
    "# Initialize video writer\n",
    "out = utils.initialize_video_writer(output_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persona 1: 340 frames\n",
      "Persona 37: 2 frames\n"
     ]
    }
   ],
   "source": [
    "# Cargar el modelo YOLO\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Inicializar la captura de video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Diccionario para almacenar los frames de cada persona\n",
    "person_frames = {}\n",
    "\n",
    "# Procesar el video frame por frame\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Detectar personas en el frame con seguimiento\n",
    "    results = model.track(frame, persist=True, verbose=False)\n",
    "\n",
    "    # Procesar las detecciones\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            # Verificar si es una persona (clase 0)\n",
    "            if int(box.cls.item()) == 0:\n",
    "                # Obtener coordenadas del bounding box\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                \n",
    "                # Obtener ID de seguimiento\n",
    "                person_id = getattr(box, 'id', None)\n",
    "                if person_id is None:\n",
    "                    continue\n",
    "                person_id = int(person_id)\n",
    "\n",
    "                # Validar y ajustar coordenadas\n",
    "                height, width = frame.shape[:2]\n",
    "                x1 = max(0, min(x1, width - 1))\n",
    "                y2 = min(y2, height - 1)\n",
    "                y1 = max(0, min(y1, y2 - 1))  # Asegurar y1 < y2\n",
    "                x2 = max(x1 + 1, min(x2, width - 1))  # Asegurar x1 < x2\n",
    "\n",
    "                # Recortar región válida\n",
    "                if x1 >= x2 or y1 >= y2:\n",
    "                    continue\n",
    "                person_frame = frame[y1:y2, x1:x2]\n",
    "\n",
    "                # Almacenar en el diccionario\n",
    "                if person_id in person_frames:\n",
    "                    person_frames[person_id].append(person_frame)\n",
    "                else:\n",
    "                    if len(person_frames) < 3:\n",
    "                        person_frames[person_id] = [person_frame]\n",
    "\n",
    "# Liberar recursos\n",
    "cap.release()\n",
    "\n",
    "# Mostrar resultados\n",
    "for person_id, frames in person_frames.items():\n",
    "    print(f\"Persona {person_id}: {len(frames)} frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_person_video(person_id, person_frames, output_path='person_video.avi', fps=30):\n",
    "    \"\"\"\n",
    "    Guarda un video con todos los frames de una persona detectada\n",
    "    \n",
    "    Args:\n",
    "        person_id (int): ID de la persona a guardar\n",
    "        person_frames (dict): Diccionario con los frames de cada persona\n",
    "        output_path (str): Ruta de salida para el video\n",
    "        fps (int): Cuadros por segundo del video resultante\n",
    "    \"\"\"\n",
    "    # Validar entrada\n",
    "    if person_id not in person_frames:\n",
    "        raise ValueError(f\"Persona ID {person_id} no encontrada en los datos\")\n",
    "        \n",
    "    frames = person_frames[person_id]\n",
    "    \n",
    "    if not frames:\n",
    "        raise ValueError(\"No hay frames para guardar\")\n",
    "    \n",
    "    # Crear directorio si no existe\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    # Obtener dimensiones del primer frame\n",
    "    height, width = frames[0].shape[:2]\n",
    "    \n",
    "    # Configurar codec y VideoWriter\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Puedes cambiar a 'MJPG' o 'MP4V' si prefieres\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    if not out.isOpened():\n",
    "        raise RuntimeError(\"No se pudo inicializar el VideoWriter. Verifica el codec y la ruta\")\n",
    "    \n",
    "    # Escribir frames\n",
    "    try:\n",
    "        for frame in frames:\n",
    "            # Verificar dimensiones y tipo de dato\n",
    "            if frame.shape[:2] != (height, width):\n",
    "                frame = cv2.resize(frame, (width, height))\n",
    "                \n",
    "            if frame.dtype != np.uint8:\n",
    "                frame = frame.astype(np.uint8)\n",
    "                \n",
    "            out.write(frame)\n",
    "            \n",
    "    except Exception as e:\n",
    "        out.release()\n",
    "        os.remove(output_path)\n",
    "        raise RuntimeError(f\"Error escribiendo frames: {str(e)}\")\n",
    "    \n",
    "    # Liberar recursos\n",
    "    out.release()\n",
    "    \n",
    "    # Verificar que el archivo se creó\n",
    "    if not os.path.exists(output_path):\n",
    "        raise RuntimeError(\"Falló la creación del archivo de video\")\n",
    "    \n",
    "    print(f\"Video guardado exitosamente en: {output_path}\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video guardado exitosamente en: videos/persona_0.avi\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso\n",
    "if person_frames:\n",
    "    save_person_video(\n",
    "        person_id=1,\n",
    "        person_frames=person_frames,\n",
    "        output_path='videos/persona_0.avi',\n",
    "        fps=30\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "yoloenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
