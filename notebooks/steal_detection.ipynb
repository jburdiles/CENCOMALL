{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nota: El modelo solo funciona con tensorflow y keras 2.15, para hacer su instalación se debe tener Python 3.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\joaqu\\miniconda3\\envs\\yoloenv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import Annotator, colors\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person:\n",
    "    def __init__(self, id, x1, y1, x2, y2):\n",
    "        self.id = id\n",
    "        self.x1 = x1\n",
    "        self.y1 = y1\n",
    "        self.x2 = x2\n",
    "        self.y2 = y2\n",
    "        self.thief = False  # Indica si la persona es sospechosa de robo\n",
    "        self.zones = list()\n",
    "\n",
    "    def set_thief_status(self, status: bool):\n",
    "        \"\"\"Actualizar estado de sospecha de la persona.\"\"\"\n",
    "        self.thief = status\n",
    "\n",
    "    def get_color(self):\n",
    "        \"\"\"Devuelve el color correspondiente a la persona según su estado.\"\"\"\n",
    "        return (0, 0, 255) if self.thief else (0, 255, 0)\n",
    "\n",
    "    def draw(self, frame):\n",
    "        \"\"\"Dibuja un rectángulo alrededor de la persona.\"\"\"\n",
    "        cv2.rectangle(frame, (self.x1, self.y1), (self.x2, self.y2), self.get_color(), 2)\n",
    "        label = \"Ladrón\" if self.thief else \"Persona\"\n",
    "        cv2.putText(frame, label, (self.x1, self.y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.get_color(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloDetector:\n",
    "    def __init__(self, yolo_model, steal_model, confidence_threshold=0.7, video_path=\"video.mp4\", \n",
    "                 individual_persons=False, output_video_path=\"output_video.mp4\",\n",
    "                 visualization=True):\n",
    "        \n",
    "        self.visualization = visualization\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.video_path = video_path\n",
    "        self.output_video_path = output_video_path  # Ruta para guardar el video procesado\n",
    "        self.individual_persons = individual_persons\n",
    "        self.people = list()\n",
    "        self.zones = list()\n",
    "\n",
    "        self.IMG_SIZE = (90, 90)\n",
    "        self.SEQUENCE_LENGTH = 160  \n",
    "\n",
    "        self.frame_queue = deque(maxlen=self.SEQUENCE_LENGTH)\n",
    "        self.person_states = defaultdict(lambda: {\"is_thief\": False, \"frames_since_last_detection\": 0})  # Almacenar estado de las personas\n",
    "\n",
    "        # Cargar modelo YOLO\n",
    "        self.yolo_model = YOLO(yolo_model)\n",
    "        # Cargar modelo LRCN para robos\n",
    "        self.steal_model = load_model(steal_model)\n",
    "\n",
    "        self.detect_thief()\n",
    "\n",
    "    def preprocess_frame(self, frame):\n",
    "        \"\"\"Preprocesa un frame para que sea compatible con el modelo.\"\"\"\n",
    "        frame = cv2.resize(frame, self.IMG_SIZE)  # Redimensionar a 90x90\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Convertir a escala de grises\n",
    "        frame = frame / 255.0  # Normalización\n",
    "        frame = np.expand_dims(frame, axis=-1)  # Añadir canal de profundidad\n",
    "        return frame\n",
    "\n",
    "    def predict_thief(self, frame):\n",
    "        input_sequence = np.expand_dims(np.array(frame), axis=0)\n",
    "        predictions = self.steal_model.predict(input_sequence)\n",
    "\n",
    "        # Obtenemos el indice del mayor valor de la predicción\n",
    "        prediction = np.argmax(predictions)\n",
    "        confidence = predictions[0][prediction]\n",
    "\n",
    "        return prediction, confidence\n",
    "\n",
    "    def detect_thief(self):\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "\n",
    "        # Obtener las propiedades del video (como el FPS y la resolución)\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "        # Configurar VideoWriter para guardar el video de salida\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"XVID\")  # Usar códec XVID\n",
    "        out = cv2.VideoWriter(self.output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret or frame is None:\n",
    "                print(\"Fin del video.\")\n",
    "                break\n",
    "\n",
    "            annotator = Annotator(frame, line_width=2)\n",
    "            results = self.yolo_model.track(frame, persist=True)\n",
    "\n",
    "            if results[0].boxes.id is not None:\n",
    "                boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "                confs = results[0].boxes.conf.cpu().numpy()\n",
    "                class_ids = results[0].boxes.cls.cpu().numpy()\n",
    "                track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "                \n",
    "                current_frame_people = set()\n",
    "\n",
    "                for box, conf, class_id, track_id in zip(boxes, confs, class_ids, track_ids):\n",
    "                    if int(class_id) == 0:  # Detectar solo personas\n",
    "                        current_frame_people.add(track_id)  # Agregar a las personas en el frame actual\n",
    "\n",
    "                        centroid_x = int((box[0] + box[2]) / 2)\n",
    "                        centroid_y = int((box[1] + box[3]) / 2)\n",
    "                        cv2.circle(frame, (centroid_x, centroid_y), 5, (0, 0, 255), -1)\n",
    "\n",
    "                        if self.individual_persons:\n",
    "                            # Extraer coordenadas del bounding box\n",
    "                            x1, y1, x2, y2 = map(int, box)  # Convertir a enteros\n",
    "\n",
    "                            # Asegurar que las coordenadas estén dentro del tamaño del frame\n",
    "                            x1, y1 = max(0, x1), max(0, y1)\n",
    "                            x2, y2 = min(width, x2), min(height, y2)\n",
    "\n",
    "                            # Recortar la región de la persona detectada\n",
    "                            person_crop = frame[y1:y2, x1:x2]\n",
    "\n",
    "                            processed_frame = self.preprocess_frame(person_crop)\n",
    "                            self.frame_queue.append(processed_frame)\n",
    "                            \n",
    "                            if len(self.frame_queue) == self.SEQUENCE_LENGTH:\n",
    "                                prediction, confidence = self.predict_thief(self.frame_queue)\n",
    "                                self.frame_queue.clear()\n",
    "\n",
    "                                if str(prediction) == \"0\" and confidence > self.confidence_threshold:\n",
    "                                    self.person_states[track_id][\"is_thief\"] = True  # Marcar como ladrón\n",
    "                                    self.person_states[track_id][\"frames_since_last_detection\"] = 0  # Reiniciar contador\n",
    "                                else:\n",
    "                                    self.person_states[track_id][\"frames_since_last_detection\"] += 1  # Incrementar contador\n",
    "\n",
    "                                # Si no se detecta como ladrón por varios frames, se deja de considerar como ladrón\n",
    "                                if self.person_states[track_id][\"frames_since_last_detection\"] > 30:  # Ajusta este valor según sea necesario\n",
    "                                    self.person_states[track_id][\"is_thief\"] = False\n",
    "\n",
    "                        # Si la persona es un ladrón, dibujar el label\n",
    "                        if self.person_states[track_id][\"is_thief\"]:\n",
    "                            label = \"Ladron\"\n",
    "                            annotator.box_label(box, label, color=(0, 0, 255))\n",
    "\n",
    "                # Limpiar estados de personas que ya no están en el frame\n",
    "                for track_id in list(self.person_states.keys()):\n",
    "                    if track_id not in current_frame_people:\n",
    "                        del self.person_states[track_id]\n",
    "\n",
    "            # Guardar el frame procesado en el video de salida\n",
    "            out.write(frame)\n",
    "            \n",
    "            if self.visualization:\n",
    "                cv2.imshow(\"object-detection-tracking\", frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        out.release()  # Liberar el VideoWriter\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 4 persons, 1 bottle, 3 chairs, 1 cell phone, 123.8ms\n",
      "Speed: 2.1ms preprocess, 123.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 bottle, 3 chairs, 1 cell phone, 137.5ms\n",
      "Speed: 2.6ms preprocess, 137.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 bottle, 3 chairs, 1 cell phone, 104.9ms\n",
      "Speed: 2.9ms preprocess, 104.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 bottle, 3 chairs, 1 microwave, 106.1ms\n",
      "Speed: 2.1ms preprocess, 106.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 1 microwave, 101.3ms\n",
      "Speed: 2.3ms preprocess, 101.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 1 microwave, 101.2ms\n",
      "Speed: 2.3ms preprocess, 101.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 bottles, 3 chairs, 1 microwave, 101.6ms\n",
      "Speed: 2.1ms preprocess, 101.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 bottles, 3 chairs, 1 microwave, 97.7ms\n",
      "Speed: 3.4ms preprocess, 97.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 bottles, 3 chairs, 1 microwave, 98.7ms\n",
      "Speed: 2.3ms preprocess, 98.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 bottles, 3 chairs, 1 microwave, 99.4ms\n",
      "Speed: 1.9ms preprocess, 99.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 bottles, 3 chairs, 1 microwave, 101.7ms\n",
      "Speed: 3.6ms preprocess, 101.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 bottles, 3 chairs, 1 microwave, 102.4ms\n",
      "Speed: 2.0ms preprocess, 102.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 bottles, 3 chairs, 1 microwave, 98.1ms\n",
      "Speed: 2.0ms preprocess, 98.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 bottles, 3 chairs, 1 microwave, 97.8ms\n",
      "Speed: 1.9ms preprocess, 97.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 bottles, 3 chairs, 1 microwave, 97.0ms\n",
      "Speed: 2.0ms preprocess, 97.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 bottles, 3 chairs, 1 microwave, 94.6ms\n",
      "Speed: 3.3ms preprocess, 94.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 bottles, 3 chairs, 1 microwave, 100.0ms\n",
      "Speed: 2.0ms preprocess, 100.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 bottles, 3 chairs, 1 microwave, 100.3ms\n",
      "Speed: 1.9ms preprocess, 100.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 bottles, 3 chairs, 1 microwave, 100.5ms\n",
      "Speed: 2.3ms preprocess, 100.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 bottles, 3 chairs, 1 microwave, 98.4ms\n",
      "Speed: 1.9ms preprocess, 98.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 bottles, 3 chairs, 1 microwave, 96.6ms\n",
      "Speed: 2.1ms preprocess, 96.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 bottles, 3 chairs, 1 microwave, 108.1ms\n",
      "Speed: 2.4ms preprocess, 108.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 bottles, 3 chairs, 1 microwave, 98.9ms\n",
      "Speed: 2.1ms preprocess, 98.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 bottles, 3 chairs, 1 microwave, 97.4ms\n",
      "Speed: 3.3ms preprocess, 97.4ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 bottles, 3 chairs, 1 microwave, 94.4ms\n",
      "Speed: 2.0ms preprocess, 94.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 bottles, 3 chairs, 1 microwave, 102.4ms\n",
      "Speed: 2.3ms preprocess, 102.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 bottles, 3 chairs, 1 microwave, 93.2ms\n",
      "Speed: 1.8ms preprocess, 93.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 bottles, 3 chairs, 1 microwave, 95.7ms\n",
      "Speed: 3.1ms preprocess, 95.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 bottles, 3 chairs, 1 microwave, 93.7ms\n",
      "Speed: 2.8ms preprocess, 93.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 bottles, 3 chairs, 1 microwave, 101.0ms\n",
      "Speed: 1.9ms preprocess, 101.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 bottles, 3 chairs, 1 microwave, 96.0ms\n",
      "Speed: 2.1ms preprocess, 96.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 bottles, 3 chairs, 1 microwave, 99.6ms\n",
      "Speed: 2.1ms preprocess, 99.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 bottles, 3 chairs, 1 microwave, 98.0ms\n",
      "Speed: 1.8ms preprocess, 98.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 1 microwave, 96.3ms\n",
      "Speed: 1.9ms preprocess, 96.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 1 microwave, 99.6ms\n",
      "Speed: 2.0ms preprocess, 99.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 1 microwave, 98.8ms\n",
      "Speed: 1.9ms preprocess, 98.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 132.3ms\n",
      "Speed: 1.8ms preprocess, 132.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 99.2ms\n",
      "Speed: 2.1ms preprocess, 99.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 96.8ms\n",
      "Speed: 1.8ms preprocess, 96.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 98.1ms\n",
      "Speed: 1.9ms preprocess, 98.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 96.2ms\n",
      "Speed: 2.0ms preprocess, 96.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 95.8ms\n",
      "Speed: 1.8ms preprocess, 95.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 100.2ms\n",
      "Speed: 2.6ms preprocess, 100.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 98.9ms\n",
      "Speed: 1.9ms preprocess, 98.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 98.0ms\n",
      "Speed: 3.8ms preprocess, 98.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 97.9ms\n",
      "Speed: 1.9ms preprocess, 97.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 94.1ms\n",
      "Speed: 3.2ms preprocess, 94.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 96.4ms\n",
      "Speed: 2.3ms preprocess, 96.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 96.5ms\n",
      "Speed: 2.1ms preprocess, 96.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 101.0ms\n",
      "Speed: 3.0ms preprocess, 101.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 107.7ms\n",
      "Speed: 2.1ms preprocess, 107.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 97.5ms\n",
      "Speed: 1.9ms preprocess, 97.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 96.7ms\n",
      "Speed: 2.2ms preprocess, 96.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 99.6ms\n",
      "Speed: 1.9ms preprocess, 99.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 98.8ms\n",
      "Speed: 2.0ms preprocess, 98.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 97.2ms\n",
      "Speed: 2.0ms preprocess, 97.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 105.5ms\n",
      "Speed: 2.3ms preprocess, 105.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 100.0ms\n",
      "Speed: 2.2ms preprocess, 100.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 101.1ms\n",
      "Speed: 2.0ms preprocess, 101.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 bottle, 3 chairs, 95.8ms\n",
      "Speed: 2.2ms preprocess, 95.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 96.0ms\n",
      "Speed: 2.7ms preprocess, 96.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 96.8ms\n",
      "Speed: 2.2ms preprocess, 96.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 108.7ms\n",
      "Speed: 3.1ms preprocess, 108.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 bottle, 3 chairs, 95.0ms\n",
      "Speed: 3.0ms preprocess, 95.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 bottle, 3 chairs, 95.4ms\n",
      "Speed: 2.5ms preprocess, 95.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 bottle, 3 chairs, 96.2ms\n",
      "Speed: 1.9ms preprocess, 96.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 bottle, 3 chairs, 95.6ms\n",
      "Speed: 1.9ms preprocess, 95.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 bottle, 3 chairs, 98.8ms\n",
      "Speed: 3.0ms preprocess, 98.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 bottle, 3 chairs, 96.1ms\n",
      "Speed: 2.1ms preprocess, 96.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 bottle, 3 chairs, 97.0ms\n",
      "Speed: 3.1ms preprocess, 97.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 bottle, 3 chairs, 97.0ms\n",
      "Speed: 2.5ms preprocess, 97.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 bottle, 3 chairs, 94.0ms\n",
      "Speed: 2.9ms preprocess, 94.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 94.5ms\n",
      "Speed: 2.4ms preprocess, 94.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 bottles, 3 chairs, 94.9ms\n",
      "Speed: 2.8ms preprocess, 94.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 bottles, 3 chairs, 97.8ms\n",
      "Speed: 3.6ms preprocess, 97.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 bottles, 3 chairs, 97.0ms\n",
      "Speed: 2.1ms preprocess, 97.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 bottles, 3 chairs, 98.3ms\n",
      "Speed: 3.3ms preprocess, 98.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 bottles, 3 chairs, 100.1ms\n",
      "Speed: 3.2ms preprocess, 100.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 bottles, 3 chairs, 99.7ms\n",
      "Speed: 1.9ms preprocess, 99.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 bottles, 3 chairs, 97.9ms\n",
      "Speed: 1.8ms preprocess, 97.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 bottles, 3 chairs, 93.9ms\n",
      "Speed: 3.0ms preprocess, 93.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 bottles, 3 chairs, 99.2ms\n",
      "Speed: 2.1ms preprocess, 99.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 bottles, 3 chairs, 100.9ms\n",
      "Speed: 2.1ms preprocess, 100.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 bottles, 3 chairs, 95.5ms\n",
      "Speed: 3.2ms preprocess, 95.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 bottles, 3 chairs, 96.8ms\n",
      "Speed: 2.2ms preprocess, 96.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 bottles, 3 chairs, 94.6ms\n",
      "Speed: 2.7ms preprocess, 94.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 96.6ms\n",
      "Speed: 1.9ms preprocess, 96.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 96.9ms\n",
      "Speed: 2.6ms preprocess, 96.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 95.1ms\n",
      "Speed: 3.4ms preprocess, 95.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 97.1ms\n",
      "Speed: 2.1ms preprocess, 97.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 96.7ms\n",
      "Speed: 1.9ms preprocess, 96.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 97.3ms\n",
      "Speed: 2.7ms preprocess, 97.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 97.1ms\n",
      "Speed: 1.9ms preprocess, 97.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 96.9ms\n",
      "Speed: 1.9ms preprocess, 96.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 97.8ms\n",
      "Speed: 2.7ms preprocess, 97.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 bottles, 3 chairs, 102.6ms\n",
      "Speed: 2.8ms preprocess, 102.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "\n",
      "0: 480x640 3 persons, 2 bottles, 3 chairs, 94.9ms\n",
      "Speed: 3.0ms preprocess, 94.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 bottles, 3 chairs, 97.3ms\n",
      "Speed: 2.3ms preprocess, 97.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 bottles, 3 chairs, 95.0ms\n",
      "Speed: 2.1ms preprocess, 95.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 bottles, 3 chairs, 93.9ms\n",
      "Speed: 2.0ms preprocess, 93.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 bottles, 3 chairs, 97.3ms\n",
      "Speed: 1.9ms preprocess, 97.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 100.5ms\n",
      "Speed: 2.5ms preprocess, 100.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 95.2ms\n",
      "Speed: 1.9ms preprocess, 95.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 109.1ms\n",
      "Speed: 1.9ms preprocess, 109.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 94.9ms\n",
      "Speed: 2.3ms preprocess, 94.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 98.3ms\n",
      "Speed: 2.8ms preprocess, 98.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 3 chairs, 94.9ms\n",
      "Speed: 2.8ms preprocess, 94.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "yolo_model = \"../src/models/yolo11n.pt\"\n",
    "steal_model = \"../src/models/lrcn_160S_90_90Q.h5\"\n",
    "video_path = '../tests/Data/Test/Normal/Normal (10).mp4'\n",
    "output_video_path = \"../outputs/steal_output.mp4\"\n",
    "individual_persons = True\n",
    "confidence_threshold = 0.9\n",
    "visualization = True\n",
    "\n",
    "detector = YoloDetector(yolo_model, steal_model, confidence_threshold, video_path, individual_persons, output_video_path, visualization)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yoloenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
